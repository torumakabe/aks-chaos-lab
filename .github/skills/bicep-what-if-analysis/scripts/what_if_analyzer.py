#!/usr/bin/env python3
"""
Bicep What-If å¤‰æ›´æŠ½å‡ºã‚¹ã‚¯ãƒªãƒ—ãƒˆ

az deployment sub what-if ã‚’å®Ÿè¡Œã—ã€å¤‰æ›´ç‚¹ã‚’æ§‹é€ åŒ–JSONã§å‡ºåŠ›ã™ã‚‹ã€‚
azd ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¨å˜ä½“ Bicep ãƒ‡ãƒ—ãƒ­ã‚¤ã®ä¸¡æ–¹ã«å¯¾å¿œã€‚

å„å¤‰æ›´ã«ã¯ bicepDefinition ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒä»˜ä¸ã•ã‚Œã€
Bicep ãƒ•ã‚¡ã‚¤ãƒ«ã§ã®å®šç¾©çŠ¶æ³ã‚’ç¢ºèªã§ãã‚‹ã€‚

ãƒ‘ã‚¿ãƒ¼ãƒ³å®šç¾©ã¯å¤–éƒ¨ JSON ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆpatterns/noise_patterns.jsonï¼‰ã§ç®¡ç†ã€‚
AI ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ›´æ–°ã™ã‚‹éš›ã¯ã€JSON ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç·¨é›†ã™ã‚‹ã€‚
"""

import argparse
import json
import logging
import os
import re
import subprocess
import sys
from datetime import datetime, timezone
from pathlib import Path
from typing import Any

# ãƒ­ã‚¬ãƒ¼è¨­å®š
logger = logging.getLogger(__name__)


def setup_logging(verbose: bool = False) -> None:
    """
    ãƒ­ã‚®ãƒ³ã‚°ã‚’è¨­å®šã™ã‚‹ã€‚

    Parameters:
        verbose: True ã®å ´åˆã¯ DEBUG ãƒ¬ãƒ™ãƒ«ã€False ã®å ´åˆã¯ WARNING ãƒ¬ãƒ™ãƒ«
    """
    level = logging.DEBUG if verbose else logging.WARNING
    logging.basicConfig(
        level=level,
        format="%(levelname)s: %(message)s",
        stream=sys.stderr,
    )


class NoisePatternLoader:
    """
    ãƒã‚¤ã‚ºãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ JSON ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€ã‚¯ãƒ©ã‚¹ã€‚

    ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯ patterns/noise_patterns.json ã§ç®¡ç†ã•ã‚Œã‚‹ã€‚
    å…±é€šãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ãƒªã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—åˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³ã®2å±¤æ§‹é€ ã€‚
    AI ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ›´æ–°ã™ã‚‹éš›ã¯ã€JSON ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç·¨é›†ã™ã‚‹ã€‚

    ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ä½¿ç”¨çŠ¶æ³ã¯ patterns/pattern_stats.json ã«è¨˜éŒ²ã•ã‚Œã‚‹ã€‚
    """

    def __init__(self, patterns_file: str | None = None) -> None:
        """
        ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’åˆæœŸåŒ–ã™ã‚‹ã€‚

        Parameters:
            patterns_file: ãƒ‘ã‚¿ãƒ¼ãƒ³ JSON ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã€‚
                           None ã®å ´åˆã¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨åŒéšå±¤ã® patterns/noise_patterns.json ã‚’ä½¿ç”¨ã€‚
        """
        if patterns_file is None:
            script_dir = Path(__file__).parent
            patterns_file = str(script_dir / "patterns" / "noise_patterns.json")

        self._patterns_file = patterns_file
        self._data: dict[str, Any] | None = None

        # ãƒ‘ã‚¿ãƒ¼ãƒ³çµ±è¨ˆãƒ•ã‚¡ã‚¤ãƒ«
        patterns_dir = Path(patterns_file).parent
        self._stats_file = str(patterns_dir / "pattern_stats.json")
        self._stats: dict[str, Any] | None = None
        self._matched_patterns: set[str] = set()  # ä»Šå›ãƒãƒƒãƒã—ãŸãƒ‘ã‚¿ãƒ¼ãƒ³

    def _load(self) -> dict[str, Any]:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ã€‚"""
        if self._data is not None:
            return self._data

        try:
            with open(self._patterns_file, encoding="utf-8") as f:
                self._data = json.load(f)
                self._validate_patterns()
        except (FileNotFoundError, json.JSONDecodeError) as e:
            logger.warning("Failed to load patterns file: %s", e)
            self._data = {"common": {}, "resource_types": {}}

        return self._data

    def _validate_patterns(self) -> None:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’æ¤œè¨¼ã—ã€è­¦å‘Šã‚’å‡ºã™ã€‚"""
        if self._data is None:
            return

        warnings = []

        # å…±é€šãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œè¨¼
        for pattern_type in [
            "readonly_patterns",
            "auto_managed_patterns",
            "custom_patterns",
        ]:
            patterns = self._data.get("common", {}).get(pattern_type, [])
            if isinstance(patterns, list):
                for idx, item in enumerate(patterns):
                    if isinstance(item, dict) and "pattern" in item:
                        pattern = item["pattern"]
                        if pattern.startswith("^properties\\."):
                            warnings.append(
                                f"âš ï¸  common.{pattern_type}[{idx}]: ãƒ‘ã‚¿ãƒ¼ãƒ³ '{pattern}' ã¯ "
                                f"'properties.' ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’å«ã‚“ã§ã„ã¾ã™ã€‚ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯è‡ªå‹•çš„ã«é™¤å»ã™ã‚‹ãŸã‚ã€"
                                f"ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰ã¯é™¤ã„ã¦ãã ã•ã„ã€‚"
                            )

        # ãƒªã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—åˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œè¨¼
        for resource_type, resource_patterns in self._data.get(
            "resource_types", {}
        ).items():
            for pattern_type in ["readonly_patterns"]:
                patterns = resource_patterns.get(pattern_type, [])
                if isinstance(patterns, list):
                    for idx, pattern in enumerate(patterns):
                        if isinstance(pattern, str) and pattern.startswith(
                            "^properties\\."
                        ):
                            warnings.append(
                                f"âš ï¸  resource_types.{resource_type}.{pattern_type}[{idx}]: "
                                f"ãƒ‘ã‚¿ãƒ¼ãƒ³ '{pattern}' ã¯ 'properties.' ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’å«ã‚“ã§ã„ã¾ã™ã€‚"
                            )

            for pattern_type in ["auto_managed_patterns", "custom_patterns"]:
                patterns = resource_patterns.get(pattern_type, [])
                if isinstance(patterns, list):
                    for idx, item in enumerate(patterns):
                        if isinstance(item, dict) and "pattern" in item:
                            pattern = item["pattern"]
                            if pattern.startswith("^properties\\."):
                                warnings.append(
                                    f"âš ï¸  resource_types.{resource_type}.{pattern_type}[{idx}]: "
                                    f"ãƒ‘ã‚¿ãƒ¼ãƒ³ '{pattern}' ã¯ 'properties.' ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’å«ã‚“ã§ã„ã¾ã™ã€‚"
                                )

            # known_defaults ã® path æ¤œè¨¼
            known_defaults = resource_patterns.get("known_defaults", [])
            if isinstance(known_defaults, list):
                for idx, item in enumerate(known_defaults):
                    if isinstance(item, dict) and "path" in item:
                        path = item["path"]
                        if path.startswith("properties."):
                            warnings.append(
                                f"âš ï¸  resource_types.{resource_type}.known_defaults[{idx}]: "
                                f"path '{path}' ã¯ 'properties.' ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’å«ã‚“ã§ã„ã¾ã™ã€‚"
                            )

        if warnings:
            logger.warning("=== ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼è­¦å‘Š ===")
            for warning in warnings:
                logger.warning(warning)
            logger.warning("=" * 40)

    def _get_common(self) -> dict[str, Any]:
        """å…±é€šãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å–å¾—ã™ã‚‹ã€‚"""
        return self._load().get("common", {})

    def _get_resource_type(self, resource_type: str) -> dict[str, Any]:
        """ãƒªã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—åˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å–å¾—ã™ã‚‹ã€‚"""
        return self._load().get("resource_types", {}).get(resource_type, {})

    def get_readonly_patterns(self, resource_type: str = "") -> list[str]:
        """readOnly ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¿”ã™ï¼ˆå…±é€š + ãƒªã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—åˆ¥ï¼‰ã€‚"""
        patterns = list(self._get_common().get("readonly_patterns", []))
        if resource_type:
            patterns.extend(
                self._get_resource_type(resource_type).get("readonly_patterns", [])
            )
        return patterns

    def get_arm_reference_patterns(self) -> list[str]:
        """ARM å‚ç…§å¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¿”ã™ï¼ˆå…±é€šã®ã¿ï¼‰ã€‚"""
        return self._get_common().get("arm_reference_patterns", [])

    def get_known_defaults(self, resource_type: str = "") -> list[tuple[str, Any, str]]:
        """æ—¢çŸ¥ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¿”ã™ï¼ˆå…±é€š + ãƒªã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—åˆ¥ï¼‰ã€‚"""
        results = []
        for item in self._get_common().get("known_defaults", []):
            results.append((item["path"], item["value"], item["description"]))
        if resource_type:
            for item in self._get_resource_type(resource_type).get(
                "known_defaults", []
            ):
                results.append((item["path"], item["value"], item["description"]))
        return results

    def get_custom_patterns(self, resource_type: str = "") -> list[tuple[str, str]]:
        """ã‚«ã‚¹ã‚¿ãƒ å€¤ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¿”ã™ï¼ˆå…±é€š + ãƒªã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—åˆ¥ï¼‰ã€‚"""
        results = []
        for item in self._get_common().get("custom_patterns", []):
            results.append((item["pattern"], item["description"]))
        if resource_type:
            for item in self._get_resource_type(resource_type).get(
                "custom_patterns", []
            ):
                results.append((item["pattern"], item["description"]))
        return results

    def get_auto_managed_patterns(
        self, resource_type: str = ""
    ) -> list[tuple[str, str]]:
        """è‡ªå‹•ç®¡ç†ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¿”ã™ï¼ˆå…±é€š + ãƒªã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—åˆ¥ï¼‰ã€‚"""
        results = []
        for item in self._get_common().get("auto_managed_patterns", []):
            results.append((item["pattern"], item["description"]))
        if resource_type:
            for item in self._get_resource_type(resource_type).get(
                "auto_managed_patterns", []
            ):
                results.append((item["pattern"], item["description"]))
        return results

    def record_pattern_match(
        self, pattern: str, category: str, resource_type: str = ""
    ) -> None:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒãƒãƒƒãƒã—ãŸã“ã¨ã‚’è¨˜éŒ²ã™ã‚‹ã€‚"""
        if resource_type:
            key = f"{resource_type}:{category}:{pattern}"
        else:
            key = f"{category}:{pattern}"
        self._matched_patterns.add(key)

    def _load_stats(self) -> dict[str, Any]:
        """çµ±è¨ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ã€‚"""
        if self._stats is not None:
            return self._stats

        try:
            with open(self._stats_file, encoding="utf-8") as f:
                self._stats = json.load(f)
        except (FileNotFoundError, json.JSONDecodeError):
            self._stats = {"patterns": {}, "lastRun": None}

        return self._stats

    def save_stats(self) -> None:
        """çµ±è¨ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã™ã‚‹ã€‚"""
        stats = self._load_stats()
        now = datetime.now(timezone.utc).isoformat()

        stats["lastRun"] = now

        # ãƒãƒƒãƒã—ãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã® lastMatched ã‚’æ›´æ–°
        for key in self._matched_patterns:
            if key not in stats["patterns"]:
                stats["patterns"][key] = {"matchCount": 0, "firstMatched": now}
            stats["patterns"][key]["lastMatched"] = now
            stats["patterns"][key]["matchCount"] = (
                stats["patterns"][key].get("matchCount", 0) + 1
            )

        try:
            with open(self._stats_file, "w", encoding="utf-8") as f:
                json.dump(stats, f, indent=2, ensure_ascii=False)
            logger.debug("Pattern stats saved to %s", self._stats_file)
        except OSError as e:
            logger.warning("Failed to save pattern stats: %s", e)

    def get_unused_patterns(self, days: int = 30) -> list[dict[str, Any]]:
        """
        æŒ‡å®šæ—¥æ•°ä»¥ä¸Šä½¿ç”¨ã•ã‚Œã¦ã„ãªã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¿”ã™ã€‚

        Parameters:
            days: æœªä½¿ç”¨ã¨ã¿ãªã™æ—¥æ•°

        Returns:
            æœªä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒªã‚¹ãƒˆ
        """
        stats = self._load_stats()
        now = datetime.now(timezone.utc)
        threshold = now - __import__("datetime").timedelta(days=days)
        unused = []

        for key, info in stats.get("patterns", {}).items():
            last_matched_str = info.get("lastMatched")
            if last_matched_str:
                last_matched = datetime.fromisoformat(last_matched_str.replace("Z", "+00:00"))
                if last_matched < threshold:
                    # ã‚­ãƒ¼å½¢å¼: "resource_type:category:pattern" ã¾ãŸã¯ "category:pattern"
                    parts = key.split(":")
                    if len(parts) >= 3:
                        resource_type = parts[0]
                        category = parts[1]
                        pattern = ":".join(parts[2:])
                    elif len(parts) == 2:
                        resource_type = None
                        category, pattern = parts
                    else:
                        continue  # ä¸æ­£ãªã‚­ãƒ¼ã¯ã‚¹ã‚­ãƒƒãƒ—
                    entry = {
                        "category": category,
                        "pattern": pattern,
                        "lastMatched": last_matched_str,
                        "daysSinceLastMatch": (now - last_matched).days,
                    }
                    if resource_type:
                        entry["resourceType"] = resource_type
                    unused.append(entry)

        return sorted(unused, key=lambda x: x["daysSinceLastMatch"], reverse=True)


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
_pattern_loader: NoisePatternLoader | None = None


def get_pattern_loader(patterns_file: str | None = None) -> NoisePatternLoader:
    """ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ­ãƒ¼ãƒ€ãƒ¼ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—ã™ã‚‹ã€‚"""
    global _pattern_loader
    if _pattern_loader is None:
        _pattern_loader = NoisePatternLoader(patterns_file)
    return _pattern_loader


def match_known_default(
    check_path: str,
    value: Any,
    known_defaults: list[tuple[str, Any, str]],
) -> str | None:
    """
    æ—¢çŸ¥ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã«ä¸€è‡´ã™ã‚‹ã‹ã‚’åˆ¤å®šã™ã‚‹ã€‚

    Parameters:
        check_path: properties. ã‚’é™¤å»ã—ãŸãƒ‘ã‚¹
        value: æ¯”è¼ƒå¯¾è±¡ã®å€¤
        known_defaults: (path, value, description) ã®ãƒªã‚¹ãƒˆ

    Returns:
        ä¸€è‡´ã—ãŸå ´åˆã¯ descriptionã€æœªä¸€è‡´ãªã‚‰ None
    """
    if value is None:
        return None

    path_end = check_path.split(".")[-1]
    for default_path, default_value, description in known_defaults:
        if path_end == default_path or check_path.endswith(default_path):
            if value == default_value:
                return description
    return None


def get_reference_info(
    path: str,
    before: Any,
    after: Any,
    bicep_definition: dict[str, Any],
    resource_type: str = "",
) -> str:
    """
    ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã®å‚è€ƒæƒ…å ±ã‚’ç”Ÿæˆã™ã‚‹ã€‚

    Bicep ç…§åˆã®æˆå¦ã«é–¢ã‚ã‚‰ãšã€ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã®æ€§è³ªã«åŸºã¥ã„ãŸå‚è€ƒæƒ…å ±ã‚’å„ªå…ˆã™ã‚‹ã€‚
    å¤–éƒ¨ YAML ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã¯ãã‚Œã‚’ä½¿ç”¨ã™ã‚‹ã€‚

    Parameters:
        path: ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ãƒ‘ã‚¹
        before: å¤‰æ›´å‰ã®å€¤
        bicep_definition: Bicep å®šç¾©æƒ…å ±
        resource_type: ãƒªã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€ã‚ˆã‚Šç²¾å¯†ãªãƒãƒƒãƒãƒ³ã‚°ã«ä½¿ç”¨ï¼‰

    Returns:
        å‚è€ƒæƒ…å ±ã®æ–‡å­—åˆ—ï¼ˆä¾‹: "âš ï¸ ã‚«ã‚¹ã‚¿ãƒ ã‚¿ã‚°"ï¼‰
    """
    loader = get_pattern_loader()

    # properties. ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’é™¤å»
    check_path = path
    if check_path.startswith("properties."):
        check_path = check_path[len("properties.") :]

    # 1. ã‚«ã‚¹ã‚¿ãƒ ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯ï¼ˆæœ€å„ªå…ˆï¼‰
    for pattern, description in loader.get_custom_patterns(resource_type):
        if re.search(pattern, check_path):
            loader.record_pattern_match(pattern, "custom_patterns", resource_type)
            return f"âš ï¸ {description}"

    # 2. readOnly ãƒã‚§ãƒƒã‚¯ï¼ˆãƒªã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—åˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä½¿ç”¨ï¼‰
    if is_readonly_property(path, resource_type):
        return "ğŸ”’ readOnlyï¼ˆAzure è‡ªå‹•è¨­å®šï¼‰"

    # 3. Azure è‡ªå‹•è¨­å®šã®å¯èƒ½æ€§ãŒé«˜ã„ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£
    for pattern, description in loader.get_auto_managed_patterns(resource_type):
        if re.search(pattern, check_path):
            loader.record_pattern_match(pattern, "auto_managed_patterns", resource_type)
            return f"ğŸ“˜ {description}"

    # 4. æ—¢çŸ¥ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ãƒã‚§ãƒƒã‚¯
    known_defaults = loader.get_known_defaults(resource_type)
    default_description = match_known_default(check_path, before, known_defaults)
    if default_description is None:
        default_description = match_known_default(check_path, after, known_defaults)
    if default_description is not None:
        return f"ğŸ“˜ {default_description}"

    # 5. Bicep å®šç¾©æƒ…å ±ï¼ˆdefined ã®å ´åˆã®ã¿è¡¨ç¤ºï¼‰
    bicep_status = bicep_definition.get("status", "unknown")
    if bicep_status == "defined":
        file_info = bicep_definition.get("file", "")
        line_info = bicep_definition.get("line", "")
        if file_info and line_info:
            return f"ğŸ“ Bicep å®šç¾©ã‚ã‚Š ({file_info}:{line_info})"
        return "ğŸ“ Bicep å®šç¾©ã‚ã‚Š"

    # æœªåˆ†é¡ã®å¤‰æ›´ï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³ã«ãƒãƒƒãƒã—ãªã„ï¼‰
    return "â“ æœªåˆ†é¡ã€‚ç¢ºèªæ¨å¥¨"


class BicepFileCache:
    """Bicep ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚"""

    def __init__(self) -> None:
        self._cache: dict[str, str] = {}
        self._loaded_dir: str | None = None

    def load(self, bicep_dir: str) -> dict[str, str]:
        """
        Bicep ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹ã€‚

        Returns:
            {ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹} ã®è¾æ›¸
        """
        if self._cache and self._loaded_dir == bicep_dir:
            return self._cache

        self._cache.clear()
        self._loaded_dir = bicep_dir

        bicep_path = Path(bicep_dir)
        if not bicep_path.exists():
            return {}

        for bicep_file in bicep_path.rglob("*.bicep"):
            try:
                self._cache[str(bicep_file)] = bicep_file.read_text(encoding="utf-8")
            except (IOError, UnicodeDecodeError):
                continue

        return self._cache


# ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
_bicep_cache = BicepFileCache()


def load_bicep_files(bicep_dir: str) -> dict[str, str]:
    """
    Bicep ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹ã€‚

    Returns:
        {ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹} ã®è¾æ›¸
    """
    return _bicep_cache.load(bicep_dir)


def extract_search_terms(
    property_path: str,
) -> tuple[str, list[str], list[tuple[str, int]]]:
    """
    ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ãƒ‘ã‚¹ã‹ã‚‰æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€è¦ªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã€é…åˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æƒ…å ±ã‚’æŠ½å‡ºã™ã‚‹ã€‚

    Returns:
        tuple[str, list[str], list[tuple[str, int]]]:
            - æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
            - è¦ªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ãƒªã‚¹ãƒˆï¼ˆé…åˆ—åã®ã¿ï¼‰
            - é…åˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æƒ…å ±ã®ãƒªã‚¹ãƒˆï¼ˆé…åˆ—å, ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼‰

    Examples:
        "tags.CostControl" -> ("CostControl", ["tags"], [])
        "properties.networkSecurityGroup" -> ("networkSecurityGroup", [], [])
        "properties.subnets.1.properties.networkSecurityGroup"
            -> ("networkSecurityGroup", ["subnets"], [("subnets", 1)])
        "properties.agentPoolProfiles.0.securityProfile"
            -> ("securityProfile", ["agentPoolProfiles"], [("agentPoolProfiles", 0)])
        "properties.agentPoolProfiles.0.count"
            -> ("count", ["agentPoolProfiles"], [("agentPoolProfiles", 0)])
    """
    parts = property_path.split(".")

    # é…åˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æƒ…å ±ã‚’æŠ½å‡º
    array_indices: list[tuple[str, int]] = []
    for i, part in enumerate(parts):
        if part.isdigit() and i > 0:
            # ç›´å‰ã®éƒ¨åˆ†ãŒé…åˆ—å
            array_name = parts[i - 1]
            if array_name not in ("properties",):
                array_indices.append((array_name, int(part)))

    # æ„å‘³ã®ã‚ã‚‹éƒ¨åˆ†ï¼ˆæ•°å­—ã¨ properties ã‚’é™¤å¤–ï¼‰ã‚’æŠ½å‡º
    meaningful_parts = [
        p for p in parts if not p.isdigit() and p not in ("properties",)
    ]

    if not meaningful_parts:
        return parts[-1], [], array_indices

    # æœ€å¾Œã®éƒ¨åˆ†ãŒæ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€ãã‚Œä»¥å¤–ãŒè¦ªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
    search_term = meaningful_parts[-1]
    parent_context = meaningful_parts[:-1]

    return search_term, parent_context, array_indices


def extract_search_term(property_path: str) -> str:
    """
    ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ãƒ‘ã‚¹ã‹ã‚‰æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºã™ã‚‹ï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ç¶­æŒï¼‰ã€‚

    Examples:
        "tags.CostControl" -> "CostControl"
        "properties.networkSecurityGroup" -> "networkSecurityGroup"
        "properties.subnets.1.properties.networkSecurityGroup" -> "networkSecurityGroup"
        "properties.agentPoolProfiles.0.count" -> "count"
    """
    term, _, _ = extract_search_terms(property_path)
    return term


def get_bicep_resource_pattern(resource_type: str) -> str | None:
    """
    ãƒªã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ã‹ã‚‰ Bicep ãƒªã‚½ãƒ¼ã‚¹å®£è¨€ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç”Ÿæˆã™ã‚‹ã€‚

    Parameters:
        resource_type: Azure ãƒªã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ï¼ˆä¾‹: Microsoft.Network/publicIPAddressesï¼‰

    Returns:
        Bicep ãƒªã‚½ãƒ¼ã‚¹å®£è¨€ã®æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³ã€ã¾ãŸã¯ None
    """
    if not resource_type:
        return None

    # Microsoft.Network/publicIPAddresses -> 'Microsoft.Network/publicIPAddresses@
    # ãƒªã‚½ãƒ¼ã‚¹å®£è¨€ã¯ resource xxx 'Microsoft.xxx/yyy@api-version' ã®å½¢å¼
    return f"'{resource_type}@"


def is_inside_parent_block(
    lines: list[str], target_line: int, parent_context: list[str]
) -> bool:
    """
    æŒ‡å®šè¡ŒãŒè¦ªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ–ãƒ­ãƒƒã‚¯å†…ã«ã‚ã‚‹ã‹ã‚’æ¤œè¨¼ã™ã‚‹ã€‚

    æ³¢æ‹¬å¼§ã¨è§’æ‹¬å¼§ã®ãƒã‚¹ãƒˆã‚’è¿½è·¡ã—ã€target_line ãŒ parent_context ã§å§‹ã¾ã‚‹
    ãƒ–ãƒ­ãƒƒã‚¯å†…ã«ã‚ã‚‹ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹ã€‚

    Parameters:
        lines: ãƒ•ã‚¡ã‚¤ãƒ«ã®è¡Œãƒªã‚¹ãƒˆ
        target_line: æ¤œè¨¼å¯¾è±¡ã®è¡Œç•ªå·ï¼ˆ1-indexedï¼‰
        parent_context: è¦ªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ãƒªã‚¹ãƒˆï¼ˆä¾‹: ['agentPoolProfiles']ï¼‰

    Returns:
        True: è¦ªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ–ãƒ­ãƒƒã‚¯å†…ã«ã‚ã‚‹
        False: è¦ªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ–ãƒ­ãƒƒã‚¯å†…ã«ãªã„
    """
    if not parent_context:
        return True

    # æœ€ã‚‚è¿‘ã„è¦ªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨
    parent = parent_context[-1]

    # target_line ã‚ˆã‚Šå‰ã®è¡Œã‚’é€†é †ã«æ¢ç´¢ã—ã€è¦ªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ–ãƒ­ãƒƒã‚¯é–‹å§‹ã‚’æ¢ã™
    target_idx = target_line - 1  # 0-indexed

    # è¦ªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®å®šç¾©è¡Œã‚’æ¢ã™
    parent_line_idx = -1
    for i in range(target_idx - 1, -1, -1):
        line = lines[i]
        stripped = line.strip()
        if stripped.startswith(f"{parent}:") or stripped.startswith(f"{parent} :"):
            parent_line_idx = i
            break

    if parent_line_idx == -1:
        # è¦ªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚‰ãªã„
        return False

    # è¦ªè¡Œã‹ã‚‰ target_line ã¾ã§ã®æ‹¬å¼§ã‚’è¿½è·¡
    parent_line = lines[parent_line_idx]

    # è¦ªè¡Œã§é–‹å§‹ã•ã‚ŒãŸæ‹¬å¼§ã®æ•°
    open_brace = parent_line.count("{") - parent_line.count("}")
    open_bracket = parent_line.count("[") - parent_line.count("]")

    # è¦ªè¡Œã‹ã‚‰ target_line ã¾ã§ã®é–“ã§æ‹¬å¼§ã‚’è¿½è·¡
    for j in range(parent_line_idx + 1, target_idx):
        check_line = lines[j]
        open_brace += check_line.count("{") - check_line.count("}")
        open_bracket += check_line.count("[") - check_line.count("]")

        # è¦ªãƒ–ãƒ­ãƒƒã‚¯ãŒé–‰ã˜ãŸå ´åˆï¼ˆä¸¡æ–¹ã®ã‚«ã‚¦ãƒ³ãƒˆãŒ0ä»¥ä¸‹ã«ãªã£ãŸå ´åˆï¼‰
        # target_line ã«åˆ°é”ã™ã‚‹å‰ã«é–‰ã˜ã¦ã„ã‚Œã°ã€target_line ã¯è¦ªãƒ–ãƒ­ãƒƒã‚¯å¤–
        if open_brace <= 0 and open_bracket <= 0:
            return False

    # target_line ã«åˆ°é”ã—ã¦ã‚‚è¦ªãƒ–ãƒ­ãƒƒã‚¯ãŒé–‹ã„ã¦ã„ã‚Œã°ã€ãƒ–ãƒ­ãƒƒã‚¯å†…
    return open_brace > 0 or open_bracket > 0


def find_array_element_range(
    lines: list[str], array_name: str, element_index: int, start_search: int = 0
) -> tuple[int, int] | None:
    """
    Bicep ãƒ•ã‚¡ã‚¤ãƒ«å†…ã§é…åˆ—ã®ç‰¹å®šã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®è¦ç´ ç¯„å›²ã‚’è¦‹ã¤ã‘ã‚‹ã€‚

    Parameters:
        lines: ãƒ•ã‚¡ã‚¤ãƒ«ã®è¡Œãƒªã‚¹ãƒˆ
        array_name: é…åˆ—åï¼ˆä¾‹: 'subnets'ï¼‰
        element_index: è¦ç´ ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆ0-basedï¼‰
        start_search: æ¤œç´¢é–‹å§‹è¡Œï¼ˆ0-indexedï¼‰

    Returns:
        (é–‹å§‹è¡Œ, çµ‚äº†è¡Œ) ã®ã‚¿ãƒ—ãƒ«ï¼ˆ1-indexedï¼‰ã€è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ None
    """
    # é…åˆ—å®šç¾©ã‚’æ¢ã™
    array_start_idx = -1
    for i in range(start_search, len(lines)):
        line = lines[i]
        stripped = line.strip()
        if stripped.startswith(f"{array_name}:") or stripped.startswith(f"{array_name} :"):
            array_start_idx = i
            break

    if array_start_idx == -1:
        return None

    # é…åˆ—ã®é–‹å§‹ï¼ˆ[ï¼‰ã‚’æ¢ã™
    bracket_start_idx = -1
    for i in range(array_start_idx, min(array_start_idx + 3, len(lines))):
        if "[" in lines[i]:
            bracket_start_idx = i
            break

    if bracket_start_idx == -1:
        return None

    # é…åˆ—è¦ç´ ã‚’è¿½è·¡ï¼ˆæ³¢æ‹¬å¼§ã§åŒºåˆ‡ã‚‰ã‚ŒãŸè¦ç´ ã‚’æ•°ãˆã‚‹ï¼‰
    current_element = -1
    element_start = -1
    brace_depth = 0
    in_element = False

    for i in range(bracket_start_idx, len(lines)):
        line = lines[i]

        for char_idx, char in enumerate(line):
            if char == "[" and i == bracket_start_idx:
                # é…åˆ—ã®é–‹å§‹
                continue
            elif char == "]" and brace_depth == 0:
                # é…åˆ—ã®çµ‚äº†
                return None
            elif char == "{":
                if brace_depth == 0:
                    # æ–°ã—ã„è¦ç´ ã®é–‹å§‹
                    current_element += 1
                    if current_element == element_index:
                        element_start = i + 1  # 1-indexed
                        in_element = True
                brace_depth += 1
            elif char == "}":
                brace_depth -= 1
                if brace_depth == 0 and in_element:
                    # å¯¾è±¡è¦ç´ ã®çµ‚äº†
                    return (element_start, i + 1)  # 1-indexed

    return None


def is_inside_array_element(
    lines: list[str],
    target_line: int,
    array_indices: list[tuple[str, int]],
    resource_ranges: list[tuple[int, int]],
) -> bool:
    """
    æŒ‡å®šè¡ŒãŒé…åˆ—ã®ç‰¹å®šã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®è¦ç´ å†…ã«ã‚ã‚‹ã‹ã‚’æ¤œè¨¼ã™ã‚‹ã€‚

    Parameters:
        lines: ãƒ•ã‚¡ã‚¤ãƒ«ã®è¡Œãƒªã‚¹ãƒˆ
        target_line: æ¤œè¨¼å¯¾è±¡ã®è¡Œç•ªå·ï¼ˆ1-indexedï¼‰
        array_indices: é…åˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æƒ…å ±ã®ãƒªã‚¹ãƒˆï¼ˆé…åˆ—å, ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼‰
        resource_ranges: ãƒªã‚½ãƒ¼ã‚¹ãƒ–ãƒ­ãƒƒã‚¯ç¯„å›²ã®ãƒªã‚¹ãƒˆ

    Returns:
        True: ã™ã¹ã¦ã®é…åˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ¡ä»¶ã‚’æº€ãŸã™
        False: æ¡ä»¶ã‚’æº€ãŸã•ãªã„
    """
    if not array_indices:
        return True

    # ãƒªã‚½ãƒ¼ã‚¹ãƒ–ãƒ­ãƒƒã‚¯å†…ã®é–‹å§‹ä½ç½®ã‚’å–å¾—
    start_search = 0
    for start, end in resource_ranges:
        if start <= target_line <= end:
            start_search = start - 1  # 0-indexed
            break

    # å„é…åˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ¤œè¨¼
    for array_name, element_index in array_indices:
        element_range = find_array_element_range(
            lines, array_name, element_index, start_search
        )
        if element_range is None:
            # é…åˆ—è¦ç´ ãŒè¦‹ã¤ã‹ã‚‰ãªã„ = å®šç¾©ã•ã‚Œã¦ã„ãªã„
            return False

        elem_start, elem_end = element_range
        if not (elem_start <= target_line <= elem_end):
            # target_line ãŒã“ã®é…åˆ—è¦ç´ ã®ç¯„å›²å¤–
            return False

    return True


def find_resource_block_range(
    lines: list[str], resource_type: str
) -> list[tuple[int, int]]:
    """
    Bicep ãƒ•ã‚¡ã‚¤ãƒ«å†…ã§ç‰¹å®šã®ãƒªã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ã®å®šç¾©ãƒ–ãƒ­ãƒƒã‚¯ç¯„å›²ã‚’è¦‹ã¤ã‘ã‚‹ã€‚

    Parameters:
        lines: ãƒ•ã‚¡ã‚¤ãƒ«ã®è¡Œãƒªã‚¹ãƒˆ
        resource_type: Azure ãƒªã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—

    Returns:
        (é–‹å§‹è¡Œ, çµ‚äº†è¡Œ) ã®ãƒªã‚¹ãƒˆï¼ˆ1-indexedï¼‰
    """
    pattern = get_bicep_resource_pattern(resource_type)
    if not pattern:
        return []

    ranges = []
    i = 0
    while i < len(lines):
        line = lines[i]
        # ãƒªã‚½ãƒ¼ã‚¹å®£è¨€ã‚’æ¤œå‡º
        if "resource " in line and pattern in line:
            start_line = i + 1  # 1-indexed
            # ãƒ–ãƒ­ãƒƒã‚¯ã®çµ‚äº†ã‚’æ¢ã™ï¼ˆæ³¢æ‹¬å¼§ã®ãƒã‚¹ãƒˆã‚’è¿½è·¡ï¼‰
            brace_count = 0
            found_open = False
            end_line = start_line

            for j in range(i, len(lines)):
                for char in lines[j]:
                    if char == "{":
                        brace_count += 1
                        found_open = True
                    elif char == "}":
                        brace_count -= 1

                if found_open and brace_count == 0:
                    end_line = j + 1  # 1-indexed
                    break

            ranges.append((start_line, end_line))
            i = end_line
        else:
            i += 1

    return ranges


def find_bicep_definition(
    property_path: str, bicep_dir: str = "./infra", resource_type: str = ""
) -> dict[str, Any]:
    """
    ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ãŒ Bicep ãƒ•ã‚¡ã‚¤ãƒ«ã§å®šç¾©ã•ã‚Œã¦ã„ã‚‹ã‹æ¤œç´¢ã™ã‚‹ã€‚

    è¦ªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆä¾‹: agentPoolProfilesï¼‰ã‚’è€ƒæ…®ã—ã€
    éšå±¤æ§‹é€ ãŒä¸€è‡´ã™ã‚‹ãƒãƒƒãƒã‚’å„ªå…ˆã™ã‚‹ã€‚
    resource_type ãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆã€è©²å½“ãƒªã‚½ãƒ¼ã‚¹ã®å®šç¾©ãƒ–ãƒ­ãƒƒã‚¯å†…ã®ã¿ã‚’æ¤œç´¢ã™ã‚‹ã€‚

    Returns:
        {
            "status": "defined" | "notDefined" | "unknown",
            "file": "infra/modules/aks.bicep" | null,
            "line": 123 | null,
            "context": "tags: { ... }" | null
        }
    """
    bicep_files = load_bicep_files(bicep_dir)
    if not bicep_files:
        return {
            "status": "unknown",
            "file": None,
            "line": None,
            "context": None,
            "reason": "No Bicep files found",
        }

    search_term, parent_context, array_indices = extract_search_terms(property_path)
    if not search_term:
        return {
            "status": "unknown",
            "file": None,
            "line": None,
            "context": None,
            "reason": "Could not extract search term",
        }

    matches: list[dict[str, Any]] = []
    context_matches: list[dict[str, Any]] = []

    for file_path, content in bicep_files.items():
        lines = content.split("\n")

        # ãƒªã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã€è©²å½“ãƒ–ãƒ­ãƒƒã‚¯ç¯„å›²ã‚’å–å¾—
        resource_ranges: list[tuple[int, int]] = []
        if resource_type:
            resource_ranges = find_resource_block_range(lines, resource_type)
            # ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«è©²å½“ãƒªã‚½ãƒ¼ã‚¹ãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            if not resource_ranges:
                continue

        for line_num, line in enumerate(lines, start=1):
            # ãƒªã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã€ãƒ–ãƒ­ãƒƒã‚¯å†…ã‹ãƒã‚§ãƒƒã‚¯
            if resource_type and resource_ranges:
                in_resource_block = any(
                    start <= line_num <= end for start, end in resource_ranges
                )
                if not in_resource_block:
                    continue

            # ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£åãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
            # ã‚³ãƒ¡ãƒ³ãƒˆè¡Œã¯é™¤å¤–
            stripped = line.strip()
            if stripped.startswith("//"):
                continue

            # æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒã‚ã‚‹å ´åˆ
            if search_term in line:
                # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ï¼ˆå‰å¾Œã®è¡Œã‚’æ¢ç´¢ï¼‰
                # è¦ªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®æ¤œè¨¼ç”¨ã«åºƒã‚ã®ç¯„å›²ã‚’å–å¾—
                context_start = max(0, line_num - 50)
                context_end = min(len(lines), line_num + 5)
                extended_context = "\n".join(lines[context_start:context_end])

                # è¡¨ç¤ºç”¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆå‰å¾Œ2è¡Œï¼‰
                display_start = max(0, line_num - 3)
                display_end = min(len(lines), line_num + 2)
                display_context = "\n".join(lines[display_start:display_end])

                match_info = {
                    "file": file_path,
                    "line": line_num,
                    "context": display_context,
                    "extended_context": extended_context,
                }

                # è¦ªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚‹å ´åˆã€ãã®ãƒ–ãƒ­ãƒƒã‚¯å†…ã«ã‚ã‚‹ã‹å³å¯†ã«æ¤œè¨¼
                if parent_context:
                    # æ³¢æ‹¬å¼§ã®ãƒã‚¹ãƒˆã‚’è¿½è·¡ã—ã¦ã€è¦ªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ–ãƒ­ãƒƒã‚¯å†…ã«ã‚ã‚‹ã‹ç¢ºèª
                    if not is_inside_parent_block(lines, line_num, parent_context):
                        matches.append(match_info)
                        continue

                    # é…åˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒã‚ã‚‹å ´åˆã€ç‰¹å®šã®è¦ç´ å†…ã«ã‚ã‚‹ã‹æ¤œè¨¼
                    if array_indices:
                        if not is_inside_array_element(
                            lines, line_num, array_indices, resource_ranges
                        ):
                            matches.append(match_info)
                            continue

                    context_matches.append(match_info)
                else:
                    # é…åˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒã‚ã‚‹å ´åˆã€ç‰¹å®šã®è¦ç´ å†…ã«ã‚ã‚‹ã‹æ¤œè¨¼
                    if array_indices:
                        if is_inside_array_element(
                            lines, line_num, array_indices, resource_ranges
                        ):
                            context_matches.append(match_info)
                        else:
                            matches.append(match_info)
                    else:
                        matches.append(match_info)

    # è¦ªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«ãƒãƒƒãƒã—ãŸã‚‚ã®ã‚’å„ªå…ˆ
    if context_matches:
        if len(context_matches) == 1:
            return {
                "status": "defined",
                "file": context_matches[0]["file"],
                "line": context_matches[0]["line"],
                "context": context_matches[0]["context"],
                "searchTerm": search_term,
                "parentContext": parent_context,
            }
        # è¤‡æ•°ã®è¦ªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒƒãƒãŒã‚ã‚‹å ´åˆ
        return {
            "status": "unknown",
            "file": context_matches[0]["file"],
            "line": context_matches[0]["line"],
            "context": context_matches[0]["context"],
            "matchCount": len(context_matches),
            "searchTerm": search_term,
            "parentContext": parent_context,
            "reason": f"Multiple context matches found ({len(context_matches)})",
        }

    # è¦ªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒƒãƒãŒãªã„å ´åˆ
    if not matches:
        return {
            "status": "notDefined",
            "file": None,
            "line": None,
            "context": None,
            "searchTerm": search_term,
            "parentContext": parent_context,
        }

    # è¦ªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚‹ã®ã«è¦ªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒƒãƒãŒãªã„å ´åˆã¯ notDefined
    # ï¼ˆç•°ãªã‚‹éšå±¤ã§åŒåãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ãŒå®šç¾©ã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰
    if parent_context:
        return {
            "status": "notDefined",
            "file": None,
            "line": None,
            "context": None,
            "searchTerm": search_term,
            "parentContext": parent_context,
            "reason": f"Found {len(matches)} match(es) but none in {parent_context} context",
        }

    if len(matches) == 1:
        return {
            "status": "defined",
            "file": matches[0]["file"],
            "line": matches[0]["line"],
            "context": matches[0]["context"],
            "searchTerm": search_term,
        }

    # è¤‡æ•°ãƒãƒƒãƒã®å ´åˆã¯æœ€åˆã®ã‚‚ã®ã‚’è¿”ã—ã€unknown ã¨ã™ã‚‹
    return {
        "status": "unknown",
        "file": matches[0]["file"],
        "line": matches[0]["line"],
        "context": matches[0]["context"],
        "matchCount": len(matches),
        "searchTerm": search_term,
        "reason": f"Multiple matches found ({len(matches)})",
    }


def get_azd_env_values() -> dict[str, str]:
    """azd env get-values ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’å–å¾—ã™ã‚‹ã€‚"""
    try:
        result = subprocess.run(
            ["azd", "env", "get-values"],
            capture_output=True,
            text=True,
            check=True,
        )
        values = {}
        for line in result.stdout.strip().split("\n"):
            if "=" in line:
                key, _, value = line.partition("=")
                # ã‚¯ã‚©ãƒ¼ãƒˆã‚’é™¤å»
                values[key] = value.strip("\"'")
        return values
    except (subprocess.CalledProcessError, FileNotFoundError):
        return {}


def detect_azd_project() -> tuple[bool, dict[str, str]]:
    """azd ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‹ã©ã†ã‹ã‚’æ¤œå‡ºã—ã€ç’°å¢ƒå¤‰æ•°ã‚’è¿”ã™ã€‚"""
    if not os.path.exists("azure.yaml"):
        return False, {}

    env_values = get_azd_env_values()
    if not env_values:
        return False, {}

    return True, env_values


def run_what_if(
    template: str,
    location: str,
    subscription: str | None = None,
    parameters: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """az deployment sub what-if ã‚’å®Ÿè¡Œã—ã€çµæœã‚’è¿”ã™ã€‚"""
    cmd = [
        "az",
        "deployment",
        "sub",
        "what-if",
        "--location",
        location,
        "--template-file",
        template,
        "--output",
        "json",
        "--no-pretty-print",
    ]

    if subscription:
        cmd.extend(["--subscription", subscription])

    if parameters:
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ key=value å½¢å¼ã§æ¸¡ã™
        for key, value in parameters.items():
            cmd.extend(["--parameters", f"{key}={value}"])

    result = subprocess.run(cmd, capture_output=True, text=True)

    if result.returncode != 0:
        # ã‚¨ãƒ©ãƒ¼ã§ã‚‚ JSON ãŒè¿”ã‚‹å ´åˆãŒã‚ã‚‹
        try:
            return json.loads(result.stdout)
        except json.JSONDecodeError:
            raise RuntimeError(f"what-if failed: {result.stderr}")

    return json.loads(result.stdout)


def is_readonly_property(path: str, resource_type: str = "") -> bool:
    """ãƒ‘ã‚¹ãŒ ARM å…±é€š readOnly ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹ã€‚"""
    loader = get_pattern_loader()

    # properties. ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’é™¤å»ã—ã¦åˆ¤å®š
    check_path = path
    if check_path.startswith("properties."):
        check_path = check_path[len("properties.") :]

    for pattern in loader.get_readonly_patterns(resource_type):
        if re.search(pattern, check_path):
            loader.record_pattern_match(pattern, "readonly_patterns", resource_type)
            return True
    return False


def contains_arm_reference(value: Any) -> bool:
    """å€¤ã« ARM å‚ç…§å¼ãŒå«ã¾ã‚Œã‚‹ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹ã€‚"""
    loader = get_pattern_loader()

    if not isinstance(value, str):
        return False

    for pattern in loader.get_arm_reference_patterns():
        if re.search(pattern, value):
            loader.record_pattern_match(pattern, "arm_reference_patterns")
            return True
    return False


def evaluate_property_change(
    path: str, change_type: str, before: Any, after: Any, resource_type: str = ""
) -> dict[str, Any]:
    """
    ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£å¤‰æ›´ã‚’è©•ä¾¡ã—ã€evaluation ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¿”ã™ã€‚

    Returns:
        {
            "status": "pending" | "noise_confirmed" | "drift_candidate",
            "reason": null | "readOnly" | "armReference" | "noEffect",
            "confidence": "high" | "low"
        }
    """
    # NoEffect ã¯å½±éŸ¿ãªã—ï¼ˆARM ãŒç„¡è¦–ã™ã‚‹å¤‰æ›´ï¼‰
    if change_type == "NoEffect":
        return {
            "status": "noise_confirmed",
            "reason": "noEffect",
            "confidence": "high",
        }

    # ARM å…±é€š readOnly ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ï¼ˆãƒªã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—åˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä½¿ç”¨ï¼‰
    if is_readonly_property(path, resource_type):
        return {
            "status": "noise_confirmed",
            "reason": "readOnly",
            "confidence": "high",
        }

    # ARM å‚ç…§å¼ã‚’å«ã‚€å ´åˆ
    if contains_arm_reference(before) or contains_arm_reference(after):
        return {
            "status": "noise_confirmed",
            "reason": "armReference",
            "confidence": "high",
        }

    # ãã‚Œä»¥å¤–ã¯ pendingï¼ˆå¾Œç¶šã‚¹ãƒ†ãƒƒãƒ—ã§è©•ä¾¡ãŒå¿…è¦ï¼‰
    return {
        "status": "pending",
        "reason": None,
        "confidence": None,
    }


def flatten_property_changes(
    delta: list[dict[str, Any]] | None,
    prefix: str = "",
    bicep_dir: str = "./infra",
    resource_type: str = "",
) -> list[dict[str, Any]]:
    """ãƒã‚¹ãƒˆã•ã‚ŒãŸãƒ—ãƒ­ãƒ‘ãƒ†ã‚£å¤‰æ›´ã‚’ãƒ•ãƒ©ãƒƒãƒˆåŒ–ã—ã€evaluation ã¨ bicepDefinition ã‚’ä»˜ä¸ã™ã‚‹ã€‚"""
    if not delta:
        return []

    changes = []

    for item in delta:
        path = item.get("path", "")
        full_path = f"{prefix}.{path}" if prefix else path
        change_type = item.get("propertyChangeType", "Unknown")

        # å­è¦ç´ ãŒã‚ã‚‹å ´åˆã¯å†å¸°
        children = item.get("children", [])
        if children:
            changes.extend(
                flatten_property_changes(children, full_path, bicep_dir, resource_type)
            )
        else:
            before = item.get("before")
            after = item.get("after")
            evaluation = evaluate_property_change(
                full_path, change_type, before, after, resource_type
            )

            # Bicep ç…§åˆï¼ˆãƒªã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ã‚’æ¸¡ã—ã¦æ­£ç¢ºãªãƒãƒƒãƒã‚’è¡Œã†ï¼‰
            bicep_definition = find_bicep_definition(
                full_path, bicep_dir, resource_type
            )

            # å‚è€ƒæƒ…å ±ã‚’ç”Ÿæˆ
            reference_info = get_reference_info(
                full_path,
                before,
                after,
                bicep_definition,
                resource_type,
            )

            changes.append(
                {
                    "path": full_path,
                    "changeType": change_type,
                    "before": before,
                    "after": after,
                    "evaluation": evaluation,
                    "bicepDefinition": bicep_definition,
                    "referenceInfo": reference_info,
                }
            )

    return changes


def extract_resource_changes(
    what_if_result: dict[str, Any], bicep_dir: str = "./infra"
) -> list[dict[str, Any]]:
    """what-if çµæœã‹ã‚‰ãƒªã‚½ãƒ¼ã‚¹å¤‰æ›´ã‚’æŠ½å‡ºã™ã‚‹ã€‚"""
    changes = []

    for change in what_if_result.get("changes", []):
        resource_id = change.get("resourceId", "")
        change_type = change.get("changeType", "Unknown")

        # ãƒªã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ã¨åå‰ã‚’æŠ½å‡º
        parts = resource_id.split("/")
        resource_name = parts[-1] if parts else ""

        # providers/Microsoft.xxx/resourceType/name ã®å½¢å¼ã‹ã‚‰ã‚¿ã‚¤ãƒ—ã‚’æŠ½å‡º
        # å­ãƒªã‚½ãƒ¼ã‚¹ã®å ´åˆã‚‚æ­£ã—ãæŠ½å‡ºã™ã‚‹ï¼ˆä¾‹: managedClusters/agentPoolsï¼‰
        resource_type = ""
        if "providers/" in resource_id:
            provider_idx = resource_id.find("providers/") + len("providers/")
            after_provider = resource_id[provider_idx:]
            type_parts = after_provider.split("/")
            # ã‚¿ã‚¤ãƒ—ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ã¿ã‚’æŠ½å‡ºï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ 0,1,3,5... = åå‰ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰
            # ä¾‹: Microsoft.ContainerService/managedClusters/aks-main/agentPools/system
            #     -> [Microsoft.ContainerService, managedClusters, aks-main, agentPools, system]
            #     -> Microsoft.ContainerService/managedClusters/agentPools
            if len(type_parts) >= 2:
                type_segments = [type_parts[0], type_parts[1]]  # Provider/ParentType
                # å­ãƒªã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ã‚’è¿½åŠ ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ 3, 5, 7, ...ï¼‰
                for i in range(3, len(type_parts), 2):
                    type_segments.append(type_parts[i])
                resource_type = "/".join(type_segments)

        # ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£å¤‰æ›´ã‚’ãƒ•ãƒ©ãƒƒãƒˆåŒ–ï¼ˆãƒªã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ã‚’æ¸¡ã™ï¼‰
        delta = change.get("delta", [])
        property_changes = flatten_property_changes(delta, "", bicep_dir, resource_type)

        changes.append(
            {
                "operation": change_type,
                "resourceId": resource_id,
                "resourceType": resource_type,
                "resourceName": resource_name,
                "propertyChanges": property_changes,
            }
        )

    return changes


def build_pending_evaluations(changes: list[dict[str, Any]]) -> dict[str, Any]:
    """pending çŠ¶æ…‹ã®è©•ä¾¡ã‚’ãƒªã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—åˆ¥ã«é›†è¨ˆã™ã‚‹ã€‚"""
    pending_count = 0
    by_resource_type: dict[str, int] = {}

    for change in changes:
        if change["operation"] not in ("Modify", "Delete"):
            continue

        resource_type = change["resourceType"]

        for prop_change in change.get("propertyChanges", []):
            eval_status = prop_change.get("evaluation", {}).get("status")
            if eval_status == "pending":
                pending_count += 1
                by_resource_type[resource_type] = (
                    by_resource_type.get(resource_type, 0) + 1
                )

    return {
        "count": pending_count,
        "byResourceType": by_resource_type,
    }


def build_output(
    what_if_result: dict[str, Any],
    template: str,
    location: str,
    bicep_dir: str = "./infra",
) -> dict[str, Any]:
    """å‡ºåŠ› JSON ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚"""
    changes = extract_resource_changes(what_if_result, bicep_dir)

    # ã‚µãƒãƒªãƒ¼é›†è¨ˆ
    summary = {"create": 0, "modify": 0, "delete": 0, "noChange": 0, "ignore": 0}
    for change in changes:
        op = change["operation"].lower()
        if op == "create":
            summary["create"] += 1
        elif op == "modify":
            summary["modify"] += 1
        elif op == "delete":
            summary["delete"] += 1
        elif op == "nochange":
            summary["noChange"] += 1
        elif op == "ignore":
            summary["ignore"] += 1

    # è©•ä¾¡ã‚µãƒãƒªãƒ¼
    evaluation_summary = {"noise_confirmed": 0, "pending": 0, "drift_candidate": 0}
    for change in changes:
        for prop_change in change.get("propertyChanges", []):
            status = prop_change.get("evaluation", {}).get("status", "pending")
            if status in evaluation_summary:
                evaluation_summary[status] += 1

    # Bicep ç…§åˆã‚µãƒãƒªãƒ¼
    bicep_summary = {"defined": 0, "notDefined": 0, "unknown": 0}
    for change in changes:
        for prop_change in change.get("propertyChanges", []):
            bicep_status = prop_change.get("bicepDefinition", {}).get(
                "status", "unknown"
            )
            if bicep_status in bicep_summary:
                bicep_summary[bicep_status] += 1

    # pending è©•ä¾¡ã®è©³ç´°
    pending_evaluations = build_pending_evaluations(changes)

    output = {
        "metadata": {
            "template": template,
            "location": location,
            "bicepDir": bicep_dir,
            "timestamp": datetime.now(timezone.utc).isoformat(),
        },
        "summary": summary,
        "evaluationSummary": evaluation_summary,
        "bicepSummary": bicep_summary,
        "changes": changes,
        "pendingEvaluations": pending_evaluations,
    }

    # æ³¨æ„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    if bicep_summary["notDefined"] > 0:
        output["notice"] = (
            f"â„¹ï¸ {bicep_summary['notDefined']} properties are not defined in Bicep files. "
            "Review the bicepDefinition.status='notDefined' items to determine if they "
            "represent drift (unintended changes) or noise (expected Azure-managed values)."
        )

    return output


class DisplayConfigLoader:
    """
    è¡¨ç¤ºè¨­å®šã‚’ JSON ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€ã‚¯ãƒ©ã‚¹ã€‚

    è¨­å®šã¯ patterns/display_config.json ã§ç®¡ç†ã•ã‚Œã‚‹ã€‚
    """

    def __init__(self, config_file: str | None = None) -> None:
        """
        è¨­å®šãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’åˆæœŸåŒ–ã™ã‚‹ã€‚

        Parameters:
            config_file: è¨­å®š JSON ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã€‚
                         None ã®å ´åˆã¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨åŒéšå±¤ã® patterns/display_config.json ã‚’ä½¿ç”¨ã€‚
        """
        if config_file is None:
            script_dir = Path(__file__).parent
            config_file = str(script_dir / "patterns" / "display_config.json")

        self._config_file = config_file
        self._data: dict[str, Any] | None = None

    def _load(self) -> dict[str, Any]:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ã€‚"""
        if self._data is not None:
            return self._data

        try:
            with open(self._config_file, encoding="utf-8") as f:
                self._data = json.load(f)
        except (FileNotFoundError, json.JSONDecodeError) as e:
            logger.warning("Failed to load display config file: %s", e)
            self._data = {"resource_type_display_names": {}, "filtered_resource_types": []}

        return self._data

    def get_display_names(self) -> dict[str, str]:
        """ãƒªã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ã®è¡¨ç¤ºåãƒãƒƒãƒ”ãƒ³ã‚°ã‚’å–å¾—ã™ã‚‹ã€‚"""
        return self._load().get("resource_type_display_names", {})

    def get_filtered_types(self) -> set[str]:
        """ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ãƒªã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ã®ã‚»ãƒƒãƒˆã‚’å–å¾—ã™ã‚‹ã€‚"""
        return set(self._load().get("filtered_resource_types", []))


# ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®šãƒ­ãƒ¼ãƒ€ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
_display_config_loader: DisplayConfigLoader | None = None


def get_display_config_loader(config_file: str | None = None) -> DisplayConfigLoader:
    """è¨­å®šãƒ­ãƒ¼ãƒ€ãƒ¼ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—ã™ã‚‹ã€‚"""
    global _display_config_loader
    if _display_config_loader is None:
        _display_config_loader = DisplayConfigLoader(config_file)
    return _display_config_loader


def get_resource_type_display_name(resource_type: str) -> str:
    """ãƒªã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ã®è¡¨ç¤ºåã‚’å–å¾—ã™ã‚‹ã€‚"""
    loader = get_display_config_loader()
    display_names = loader.get_display_names()
    return display_names.get(resource_type, resource_type)


def is_main_resource(resource_type: str, resource_id: str) -> bool:
    """
    azd ãŒè¡¨ç¤ºã™ã‚‹ä¸»è¦ãƒªã‚½ãƒ¼ã‚¹ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹ã€‚

    azd ã¯å­ãƒªã‚½ãƒ¼ã‚¹ã‚„è£œåŠ©çš„ãªãƒªã‚½ãƒ¼ã‚¹ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã€
    ã‚¹ã‚³ãƒ¼ãƒ—ãƒ¬ãƒ™ãƒ«ã§ãƒ‡ãƒ—ãƒ­ã‚¤ã•ã‚Œã‚‹ä¸»è¦ãƒªã‚½ãƒ¼ã‚¹ã®ã¿ã‚’è¡¨ç¤ºã™ã‚‹ã€‚

    åˆ¤å®šåŸºæº–:
    1. ãƒªã‚½ãƒ¼ã‚¹ ID ã®æœ€å¾Œã® /providers/ ã‚»ã‚°ãƒ¡ãƒ³ãƒˆä»¥é™ã§å­ãƒªã‚½ãƒ¼ã‚¹ã‚’åˆ¤å®š
       ï¼ˆæ‹¡å¼µãƒªã‚½ãƒ¼ã‚¹ã® nested providers ã«ã‚‚å¯¾å¿œï¼‰
    2. display_config.json ã® filtered_resource_types ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    """
    # ãƒªã‚½ãƒ¼ã‚¹ ID ã‹ã‚‰ã‚¹ã‚³ãƒ¼ãƒ—ã‚’åˆ¤å®š
    # å­ãƒªã‚½ãƒ¼ã‚¹ã¯ /providers/Type/name/childType/childName ã®ã‚ˆã†ãªå½¢å¼
    # æ‹¡å¼µãƒªã‚½ãƒ¼ã‚¹ã¯ .../providers/Microsoft.Xxx/.../providers/Microsoft.Yyy/... ã®å½¢å¼
    if resource_id:
        resource_id_lower = resource_id.lower()
        # æœ€å¾Œã® /providers/ ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’åŸºæº–ã«ã™ã‚‹ï¼ˆæ‹¡å¼µãƒªã‚½ãƒ¼ã‚¹å¯¾å¿œï¼‰
        # æ‹¡å¼µãƒªã‚½ãƒ¼ã‚¹ä¾‹: .../managedClusters/aks-xxx/providers/Microsoft.Chaos/targets/xxx
        last_providers_idx = resource_id_lower.rfind("/providers/")
        if last_providers_idx >= 0:
            provider_path = resource_id[last_providers_idx + len("/providers/") :]
            segments = [s for s in provider_path.split("/") if s]
            # Microsoft.Xxx, resourceType, name ã® 3 ã¤ãŒåŸºæœ¬
            # ãã‚Œä»¥ä¸Šã‚ã‚Œã°å­ãƒªã‚½ãƒ¼ã‚¹ï¼ˆæœ€å¾Œã® provider åŸºæº–ï¼‰
            if len(segments) > 3:
                return False

    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ãƒªã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ã‚’è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å–å¾—
    loader = get_display_config_loader()
    filtered_types = loader.get_filtered_types()

    if resource_type.lower() in filtered_types:
        return False

    return True


def format_azd_style_output(output_data: dict[str, Any]) -> str:
    """
    azd provision --preview é¢¨ã®ãƒ†ã‚­ã‚¹ãƒˆå‡ºåŠ›ã‚’ç”Ÿæˆã™ã‚‹ã€‚

    Args:
        output_data: build_output() ã®çµæœ

    Returns:
        azd é¢¨ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿ãƒ†ã‚­ã‚¹ãƒˆ
    """
    lines: list[str] = []

    lines.append("Resources:")
    lines.append("")

    # æ“ä½œã‚¿ã‚¤ãƒ—ã®è¡¨ç¤ºé †ã¨è¡¨ç¤ºå
    operation_display = {
        "NoChange": "Skip",
        "Ignore": "Skip",
        "Modify": "Modify",
        "Create": "Create",
        "Delete": "Delete",
    }

    # ä¸»è¦ãƒªã‚½ãƒ¼ã‚¹ã®ã¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    main_resources = [
        c
        for c in output_data["changes"]
        if is_main_resource(c["resourceType"], c.get("resourceId", ""))
    ]

    # æœ€å¤§å¹…ã‚’è¨ˆç®—ï¼ˆæ•´åˆ—ç”¨ï¼‰
    max_op_len = 8  # "Modify" ãªã©
    max_type_len = 0
    for change in main_resources:
        display_type = get_resource_type_display_name(change["resourceType"])
        if len(display_type) > max_type_len:
            max_type_len = len(display_type)

    # å„ãƒªã‚½ãƒ¼ã‚¹ã‚’å‡ºåŠ›
    for change in main_resources:
        op = change["operation"]
        display_op = operation_display.get(op) or op
        display_type = get_resource_type_display_name(change["resourceType"])
        resource_name = change["resourceName"]

        # æ•´åˆ—
        op_padded = display_op.ljust(max_op_len)
        type_padded = display_type.ljust(max_type_len)

        lines.append(f"  {op_padded} : {type_padded} : {resource_name}")

        # Skip ä»¥å¤–ã¯ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£å¤‰æ›´ã‚’è¡¨ç¤º
        if op not in ("NoChange", "Ignore") and change.get("propertyChanges"):
            for pc in change["propertyChanges"]:
                change_type = pc.get("changeType", "")
                path = pc.get("path", "")
                ref_info = pc.get("referenceInfo", "")

                # å¤‰æ›´ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸè¨˜å·
                if change_type == "Delete":
                    symbol = "-"
                elif change_type == "Create":
                    symbol = "+"
                elif change_type == "Modify":
                    symbol = "~"
                else:
                    symbol = "*"

                # å‚è€ƒæƒ…å ±ãŒã‚ã‚‹å ´åˆã¯è¡¨ç¤º
                if ref_info:
                    lines.append(f"      {symbol} {path}  {ref_info}")
                else:
                    lines.append(f"      {symbol} {path}")

    return "\n".join(lines)


def main() -> int:
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°ã€‚"""
    parser = argparse.ArgumentParser(
        description="Bicep what-if ã‚’å®Ÿè¡Œã—ã€å¤‰æ›´ç‚¹ã‚’ JSON ã§å‡ºåŠ›ã™ã‚‹"
    )
    parser.add_argument(
        "-t",
        "--template",
        help="Bicep ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ« (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ./infra/main.bicep)",
    )
    parser.add_argument("-l", "--location", help="Azure ãƒªãƒ¼ã‚¸ãƒ§ãƒ³")
    parser.add_argument("-s", "--subscription", help="ã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ ID")
    parser.add_argument(
        "--no-azd",
        action="store_true",
        help="azd è‡ªå‹•æ¤œå‡ºã‚’ç„¡åŠ¹åŒ–",
    )
    parser.add_argument(
        "-p",
        "--parameter",
        action="append",
        nargs=2,
        metavar=("KEY", "VALUE"),
        help="ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (ä¾‹: -p environmentName dev)",
    )
    parser.add_argument(
        "-b",
        "--bicep-dir",
        default="./infra",
        help="Bicep ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ./infra)",
    )
    parser.add_argument(
        "-f",
        "--format",
        choices=["json", "text"],
        default="text",
        help="å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: text ã¯ azd é¢¨, json)",
    )
    parser.add_argument(
        "-v",
        "--verbose",
        action="store_true",
        help="è©³ç´°ãªãƒ­ã‚°ã‚’å‡ºåŠ›",
    )

    args = parser.parse_args()

    # ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
    setup_logging(verbose=args.verbose)

    # azd ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¤œå‡º
    is_azd = False
    azd_values: dict[str, str] = {}
    if not args.no_azd:
        is_azd, azd_values = detect_azd_project()

    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è§£æ±º
    template = args.template
    location = args.location
    subscription = args.subscription
    parameters: dict[str, Any] = {}

    if is_azd:
        template = template or "./infra/main.bicep"
        location = location or azd_values.get("AZURE_LOCATION", "")
        subscription = subscription or azd_values.get("AZURE_SUBSCRIPTION_ID", "")

        # azd ç’°å¢ƒå¤‰æ•°ã‚’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«å¤‰æ›
        # environment ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆAZURE_ENV_NAME ã‹ã‚‰ï¼‰
        if "AZURE_ENV_NAME" in azd_values:
            parameters["environment"] = azd_values["AZURE_ENV_NAME"]
        if "AZURE_LOCATION" in azd_values:
            parameters["location"] = azd_values["AZURE_LOCATION"]
    else:
        template = template or "./main.bicep"

    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¿½åŠ 
    if args.parameter:
        for key, value in args.parameter:
            parameters[key] = value

    # å¿…é ˆãƒã‚§ãƒƒã‚¯
    if not template:
        logger.error("--template is required")
        return 1
    if not location:
        logger.error("--location is required")
        return 1
    if not os.path.exists(template):
        logger.error("Template file not found: %s", template)
        return 1

    # what-if å®Ÿè¡Œ
    try:
        what_if_result = run_what_if(
            template=template,
            location=location,
            subscription=subscription,
            parameters=parameters if parameters else None,
        )
    except RuntimeError as e:
        logger.error("what-if failed: %s", e)
        return 1

    # å‡ºåŠ›
    bicep_dir = args.bicep_dir
    output = build_output(what_if_result, template, location, bicep_dir)

    if args.format == "text":
        print(format_azd_style_output(output))
    else:
        print(json.dumps(output, indent=2, ensure_ascii=False))

    # ãƒ‘ã‚¿ãƒ¼ãƒ³çµ±è¨ˆã‚’ä¿å­˜
    loader = get_pattern_loader()
    loader.save_stats()

    # æœªä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è­¦å‘Š
    unused = loader.get_unused_patterns(days=30)
    if unused:
        logger.warning("=== æœªä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³è­¦å‘Šï¼ˆ30æ—¥ä»¥ä¸Šãƒãƒƒãƒãªã—ï¼‰ ===")
        for item in unused[:5]:  # æœ€å¤§5ä»¶è¡¨ç¤º
            logger.warning(
                "  %s: %s (æœ€çµ‚ãƒãƒƒãƒ: %dæ—¥å‰)",
                item["category"],
                item["pattern"],
                item["daysSinceLastMatch"],
            )
        if len(unused) > 5:
            logger.warning("  ... ä»– %d ä»¶", len(unused) - 5)

    return 0


if __name__ == "__main__":
    sys.exit(main())
